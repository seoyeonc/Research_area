<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2023-09-08">

<title>Research - [LLM]LLAMA2</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Research</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/sy_hub/">
 <span class="menu-text">Main_Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><strong>[LLM]</strong>LLAMA2</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block"><strong>[LLM]</strong>LLAMA2</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">September 8, 2023</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../1_studies.html" class="sidebar-item-text sidebar-link"><strong>Studies</strong></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true"><strong>Research</strong></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../2_no_category.html" class="sidebar-item-text sidebar-link"><strong>No Category</strong></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../3_pygod.html" class="sidebar-item-text sidebar-link"><strong>PYGOD</strong></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../4_llm.html" class="sidebar-item-text sidebar-link"><strong>LLM</strong></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../5_note.html" class="sidebar-item-text sidebar-link"><strong>Notes</strong></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#import" id="toc-import" class="nav-link active" data-scroll-target="#import">Import</a></li>
  <li><a href="#ì‚¬ìš©ê°€ëŠ¥í•œ-pretrainedëœ-model" id="toc-ì‚¬ìš©ê°€ëŠ¥í•œ-pretrainedëœ-model" class="nav-link" data-scroll-target="#ì‚¬ìš©ê°€ëŠ¥í•œ-pretrainedëœ-model">ì‚¬ìš©ê°€ëŠ¥í•œ pretrainedëœ model</a></li>
  <li><a href="#í…ìŠ¤íŠ¸-ìƒì„±" id="toc-í…ìŠ¤íŠ¸-ìƒì„±" class="nav-link" data-scroll-target="#í…ìŠ¤íŠ¸-ìƒì„±">í…ìŠ¤íŠ¸ ìƒì„±</a>
  <ul class="collapse">
  <li><a href="#load-a-model-tokenizer" id="toc-load-a-model-tokenizer" class="nav-link" data-scroll-target="#load-a-model-tokenizer">Load a model &amp; tokenizer</a>
  <ul class="collapse">
  <li><a href="#chat-versionì€-txt-ì£¼ê³ -ë°›ëŠ”-ëª¨ë¸" id="toc-chat-versionì€-txt-ì£¼ê³ -ë°›ëŠ”-ëª¨ë¸" class="nav-link" data-scroll-target="#chat-versionì€-txt-ì£¼ê³ -ë°›ëŠ”-ëª¨ë¸">1. chat versionì€ txt ì£¼ê³  ë°›ëŠ” ëª¨ë¸</a></li>
  <li><a href="#ë‹¨ìˆœ-txt-ìƒì„±í•˜ëŠ”-ëª¨ë¸" id="toc-ë‹¨ìˆœ-txt-ìƒì„±í•˜ëŠ”-ëª¨ë¸" class="nav-link" data-scroll-target="#ë‹¨ìˆœ-txt-ìƒì„±í•˜ëŠ”-ëª¨ë¸">2. ë‹¨ìˆœ txt ìƒì„±í•˜ëŠ” ëª¨ë¸</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#feature-extraction" id="toc-feature-extraction" class="nav-link" data-scroll-target="#feature-extraction">feature-extraction</a>
  <ul class="collapse">
  <li><a href="#ê³µì‹-ì˜ˆì œ" id="toc-ê³µì‹-ì˜ˆì œ" class="nav-link" data-scroll-target="#ê³µì‹-ì˜ˆì œ">ê³µì‹ ì˜ˆì œ</a>
  <ul class="collapse">
  <li><a href="#íŠ¹ì§•í™”-1textì—ì„œ-íŠ¹ì§•-ì¶”ì¶œ" id="toc-íŠ¹ì§•í™”-1textì—ì„œ-íŠ¹ì§•-ì¶”ì¶œ" class="nav-link" data-scroll-target="#íŠ¹ì§•í™”-1textì—ì„œ-íŠ¹ì§•-ì¶”ì¶œ">íŠ¹ì§•í™” 1(textì—ì„œ íŠ¹ì§• ì¶”ì¶œ)</a></li>
  <li><a href="#íŠ¹ì§•í™”-2í† í°í™”í•œ-í›„-íŠ¹ì§•-ì¶”ì¶œ" id="toc-íŠ¹ì§•í™”-2í† í°í™”í•œ-í›„-íŠ¹ì§•-ì¶”ì¶œ" class="nav-link" data-scroll-target="#íŠ¹ì§•í™”-2í† í°í™”í•œ-í›„-íŠ¹ì§•-ì¶”ì¶œ">íŠ¹ì§•í™” 2(í† í°í™”í•œ í›„ íŠ¹ì§• ì¶”ì¶œ)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#fine-tuning" id="toc-fine-tuning" class="nav-link" data-scroll-target="#fine-tuning">Fine-tuning</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>https://huggingface.co/Trelis</p>
<section id="import" class="level1">
<h1>Import</h1>
<div class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># !pip install -q transformers accelerate sentencepiece</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># !huggingface-cli login</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoTokenizer</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> LabelEncoder</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
</div>
</section>
<section id="ì‚¬ìš©ê°€ëŠ¥í•œ-pretrainedëœ-model" class="level1">
<h1>ì‚¬ìš©ê°€ëŠ¥í•œ pretrainedëœ model</h1>
<p>ì‚¬ìš©ê°€ëŠ¥í•œ pretrainedëœ modelë“¤ ì¢…ë¥˜ ì•„ì§ llama2ëŠ” ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì€ë“¯</p>
<pre><code>- **albert** -- [`AlbertTokenizer`] or [`AlbertTokenizerFast`] (ALBERT model)
- **align** -- [`BertTokenizer`] or [`BertTokenizerFast`] (ALIGN model)
- **bart** -- [`BartTokenizer`] or [`BartTokenizerFast`] (BART model)
- **barthez** -- [`BarthezTokenizer`] or [`BarthezTokenizerFast`] (BARThez model)
- **bartpho** -- [`BartphoTokenizer`] (BARTpho model)
- **bert** -- [`BertTokenizer`] or [`BertTokenizerFast`] (BERT model)
- **bert-generation** -- [`BertGenerationTokenizer`] (Bert Generation model)
- **bert-japanese** -- [`BertJapaneseTokenizer`] (BertJapanese model)
- **bertweet** -- [`BertweetTokenizer`] (BERTweet model)
- **big_bird** -- [`BigBirdTokenizer`] or [`BigBirdTokenizerFast`] (BigBird model)
- **bigbird_pegasus** -- [`PegasusTokenizer`] or [`PegasusTokenizerFast`] (BigBird-Pegasus model)
- **biogpt** -- [`BioGptTokenizer`] (BioGpt model)
- **blenderbot** -- [`BlenderbotTokenizer`] or [`BlenderbotTokenizerFast`] (Blenderbot model)
- **blenderbot-small** -- [`BlenderbotSmallTokenizer`] (BlenderbotSmall model)
- **blip** -- [`BertTokenizer`] or [`BertTokenizerFast`] (BLIP model)
- **blip-2** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (BLIP-2 model)
- **bloom** -- [`BloomTokenizerFast`] (BLOOM model)
- **bridgetower** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (BridgeTower model)
- **byt5** -- [`ByT5Tokenizer`] (ByT5 model)
- **camembert** -- [`CamembertTokenizer`] or [`CamembertTokenizerFast`] (CamemBERT model)
- **canine** -- [`CanineTokenizer`] (CANINE model)
- **chinese_clip** -- [`BertTokenizer`] or [`BertTokenizerFast`] (Chinese-CLIP model)
- **clap** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (CLAP model)
- **clip** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (CLIP model)
- **clipseg** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (CLIPSeg model)
- **codegen** -- [`CodeGenTokenizer`] or [`CodeGenTokenizerFast`] (CodeGen model)
- **convbert** -- [`ConvBertTokenizer`] or [`ConvBertTokenizerFast`] (ConvBERT model)
- **cpm** -- [`CpmTokenizer`] or [`CpmTokenizerFast`] (CPM model)
- **cpmant** -- [`CpmAntTokenizer`] (CPM-Ant model)
- **ctrl** -- [`CTRLTokenizer`] (CTRL model)
- **data2vec-text** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (Data2VecText model)
- **deberta** -- [`DebertaTokenizer`] or [`DebertaTokenizerFast`] (DeBERTa model)
- **deberta-v2** -- [`DebertaV2Tokenizer`] or [`DebertaV2TokenizerFast`] (DeBERTa-v2 model)
- **distilbert** -- [`DistilBertTokenizer`] or [`DistilBertTokenizerFast`] (DistilBERT model)
- **dpr** -- [`DPRQuestionEncoderTokenizer`] or [`DPRQuestionEncoderTokenizerFast`] (DPR model)
- **electra** -- [`ElectraTokenizer`] or [`ElectraTokenizerFast`] (ELECTRA model)
- **ernie** -- [`BertTokenizer`] or [`BertTokenizerFast`] (ERNIE model)
- **ernie_m** -- [`ErnieMTokenizer`] (ErnieM model)
- **esm** -- [`EsmTokenizer`] (ESM model)
- **flaubert** -- [`FlaubertTokenizer`] (FlauBERT model)
- **fnet** -- [`FNetTokenizer`] or [`FNetTokenizerFast`] (FNet model)
- **fsmt** -- [`FSMTTokenizer`] (FairSeq Machine-Translation model)
- **funnel** -- [`FunnelTokenizer`] or [`FunnelTokenizerFast`] (Funnel Transformer model)
- **git** -- [`BertTokenizer`] or [`BertTokenizerFast`] (GIT model)
- **gpt-sw3** -- [`GPTSw3Tokenizer`] (GPT-Sw3 model)
- **gpt2** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (OpenAI GPT-2 model)
- **gpt_bigcode** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (GPTBigCode model)
- **gpt_neo** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (GPT Neo model)
- **gpt_neox** -- [`GPTNeoXTokenizerFast`] (GPT NeoX model)
- **gpt_neox_japanese** -- [`GPTNeoXJapaneseTokenizer`] (GPT NeoX Japanese model)
- **gptj** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (GPT-J model)
- **gptsan-japanese** -- [`GPTSanJapaneseTokenizer`] (GPTSAN-japanese model)
- **groupvit** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (GroupViT model)
- **herbert** -- [`HerbertTokenizer`] or [`HerbertTokenizerFast`] (HerBERT model)
- **hubert** -- [`Wav2Vec2CTCTokenizer`] (Hubert model)
- **ibert** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (I-BERT model)
- **jukebox** -- [`JukeboxTokenizer`] (Jukebox model)
- **layoutlm** -- [`LayoutLMTokenizer`] or [`LayoutLMTokenizerFast`] (LayoutLM model)
- **layoutlmv2** -- [`LayoutLMv2Tokenizer`] or [`LayoutLMv2TokenizerFast`] (LayoutLMv2 model)
- **layoutlmv3** -- [`LayoutLMv3Tokenizer`] or [`LayoutLMv3TokenizerFast`] (LayoutLMv3 model)
- **layoutxlm** -- [`LayoutXLMTokenizer`] or [`LayoutXLMTokenizerFast`] (LayoutXLM model)
- **led** -- [`LEDTokenizer`] or [`LEDTokenizerFast`] (LED model)
- **lilt** -- [`LayoutLMv3Tokenizer`] or [`LayoutLMv3TokenizerFast`] (LiLT model)
- **llama** -- [`LlamaTokenizer`] or [`LlamaTokenizerFast`] (LLaMA model)
- **longformer** -- [`LongformerTokenizer`] or [`LongformerTokenizerFast`] (Longformer model)
- **longt5** -- [`T5Tokenizer`] or [`T5TokenizerFast`] (LongT5 model)
- **luke** -- [`LukeTokenizer`] (LUKE model)
- **lxmert** -- [`LxmertTokenizer`] or [`LxmertTokenizerFast`] (LXMERT model)
- **m2m_100** -- [`M2M100Tokenizer`] (M2M100 model)
- **marian** -- [`MarianTokenizer`] (Marian model)
- **mbart** -- [`MBartTokenizer`] or [`MBartTokenizerFast`] (mBART model)
- **mbart50** -- [`MBart50Tokenizer`] or [`MBart50TokenizerFast`] (mBART-50 model)
- **mega** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (MEGA model)
- **megatron-bert** -- [`BertTokenizer`] or [`BertTokenizerFast`] (Megatron-BERT model)
- **mgp-str** -- [`MgpstrTokenizer`] (MGP-STR model)
- **mluke** -- [`MLukeTokenizer`] (mLUKE model)
- **mobilebert** -- [`MobileBertTokenizer`] or [`MobileBertTokenizerFast`] (MobileBERT model)
- **mpnet** -- [`MPNetTokenizer`] or [`MPNetTokenizerFast`] (MPNet model)
- **mt5** -- [`MT5Tokenizer`] or [`MT5TokenizerFast`] (MT5 model)
- **mvp** -- [`MvpTokenizer`] or [`MvpTokenizerFast`] (MVP model)
- **nezha** -- [`BertTokenizer`] or [`BertTokenizerFast`] (Nezha model)
- **nllb** -- [`NllbTokenizer`] or [`NllbTokenizerFast`] (NLLB model)
- **nllb-moe** -- [`NllbTokenizer`] or [`NllbTokenizerFast`] (NLLB-MOE model)
- **nystromformer** -- [`AlbertTokenizer`] or [`AlbertTokenizerFast`] (NystrÃ¶mformer model)
- **oneformer** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (OneFormer model)
- **openai-gpt** -- [`OpenAIGPTTokenizer`] or [`OpenAIGPTTokenizerFast`] (OpenAI GPT model)
- **opt** -- [`GPT2Tokenizer`] or [`GPT2TokenizerFast`] (OPT model)
- **owlvit** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (OWL-ViT model)
- **pegasus** -- [`PegasusTokenizer`] or [`PegasusTokenizerFast`] (Pegasus model)
- **pegasus_x** -- [`PegasusTokenizer`] or [`PegasusTokenizerFast`] (PEGASUS-X model)
- **perceiver** -- [`PerceiverTokenizer`] (Perceiver model)
- **phobert** -- [`PhobertTokenizer`] (PhoBERT model)
- **pix2struct** -- [`T5Tokenizer`] or [`T5TokenizerFast`] (Pix2Struct model)
- **plbart** -- [`PLBartTokenizer`] (PLBart model)
- **prophetnet** -- [`ProphetNetTokenizer`] (ProphetNet model)
- **qdqbert** -- [`BertTokenizer`] or [`BertTokenizerFast`] (QDQBert model)
- **rag** -- [`RagTokenizer`] (RAG model)
- **realm** -- [`RealmTokenizer`] or [`RealmTokenizerFast`] (REALM model)
- **reformer** -- [`ReformerTokenizer`] or [`ReformerTokenizerFast`] (Reformer model)
- **rembert** -- [`RemBertTokenizer`] or [`RemBertTokenizerFast`] (RemBERT model)
- **retribert** -- [`RetriBertTokenizer`] or [`RetriBertTokenizerFast`] (RetriBERT model)
- **roberta** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (RoBERTa model)
- **roberta-prelayernorm** -- [`RobertaTokenizer`] or [`RobertaTokenizerFast`] (RoBERTa-PreLayerNorm model)
- **roc_bert** -- [`RoCBertTokenizer`] (RoCBert model)
- **roformer** -- [`RoFormerTokenizer`] or [`RoFormerTokenizerFast`] (RoFormer model)
- **rwkv** -- [`GPTNeoXTokenizerFast`] (RWKV model)
- **speech_to_text** -- [`Speech2TextTokenizer`] (Speech2Text model)
- **speech_to_text_2** -- [`Speech2Text2Tokenizer`] (Speech2Text2 model)
- **speecht5** -- [`SpeechT5Tokenizer`] (SpeechT5 model)
- **splinter** -- [`SplinterTokenizer`] or [`SplinterTokenizerFast`] (Splinter model)
- **squeezebert** -- [`SqueezeBertTokenizer`] or [`SqueezeBertTokenizerFast`] (SqueezeBERT model)
- **switch_transformers** -- [`T5Tokenizer`] or [`T5TokenizerFast`] (SwitchTransformers model)
- **t5** -- [`T5Tokenizer`] or [`T5TokenizerFast`] (T5 model)
- **tapas** -- [`TapasTokenizer`] (TAPAS model)
- **tapex** -- [`TapexTokenizer`] (TAPEX model)
- **transfo-xl** -- [`TransfoXLTokenizer`] (Transformer-XL model)
- **vilt** -- [`BertTokenizer`] or [`BertTokenizerFast`] (ViLT model)
- **visual_bert** -- [`BertTokenizer`] or [`BertTokenizerFast`] (VisualBERT model)
- **wav2vec2** -- [`Wav2Vec2CTCTokenizer`] (Wav2Vec2 model)
- **wav2vec2-conformer** -- [`Wav2Vec2CTCTokenizer`] (Wav2Vec2-Conformer model)
- **wav2vec2_phoneme** -- [`Wav2Vec2PhonemeCTCTokenizer`] (Wav2Vec2Phoneme model)
- **whisper** -- [`WhisperTokenizer`] or [`WhisperTokenizerFast`] (Whisper model)
- **xclip** -- [`CLIPTokenizer`] or [`CLIPTokenizerFast`] (X-CLIP model)
- **xglm** -- [`XGLMTokenizer`] or [`XGLMTokenizerFast`] (XGLM model)
- **xlm** -- [`XLMTokenizer`] (XLM model)
- **xlm-prophetnet** -- [`XLMProphetNetTokenizer`] (XLM-ProphetNet model)
- **xlm-roberta** -- [`XLMRobertaTokenizer`] or [`XLMRobertaTokenizerFast`] (XLM-RoBERTa model)
- **xlm-roberta-xl** -- [`XLMRobertaTokenizer`] or [`XLMRobertaTokenizerFast`] (XLM-RoBERTa-XL model)
- **xlnet** -- [`XLNetTokenizer`] or [`XLNetTokenizerFast`] (XLNet model)
- **xmod** -- [`XLMRobertaTokenizer`] or [`XLMRobertaTokenizerFast`] (X-MOD model)
- **yoso** -- [`AlbertTokenizer`] or [`AlbertTokenizerFast`] (YOSO model)</code></pre>
</section>
<section id="í…ìŠ¤íŠ¸-ìƒì„±" class="level1">
<h1>í…ìŠ¤íŠ¸ ìƒì„±</h1>
<p>jupyter ì—ì„œ ëŒì•„ê°ˆ ìˆ˜ ìˆë„ë¡ transformers.pipelineì˜ ì˜µì…˜ ìˆ˜ì •</p>
<ul>
<li>í•´ê²°ì±… 1.
<ul>
<li>https://stackoverflow.com/questions/73530569/pytorch-matmul-runtimeerror-addmm-impl-cpu-not-implemented-for-half</li>
<li>ìœ„ì—ì„œ ì–»ì€ ë‹µ, ë°ì´í„° íƒ€ì…ì„float16ì´ ì•„ë‹Œ float32ë¥¼ ì‚¬ìš©</li>
</ul></li>
<li>í•´ê²°ì±… 2.
<ul>
<li>device_map = â€™autoâ€™ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.</li>
<li>device_map=None ì´ default,</li>
<li>device_map = â€™autoâ€™ë¥¼ í•˜ë©´ gpu í˜¹ì€ cpuë¥¼ ìë™ìœ¼ë¡œ ì¡ëŠ”ë°, ì´ê²ƒì„ ëª»í•´ì„œ ì˜¤ë¥˜ê°€ ë‚œ ë“¯&gt;???</li>
</ul></li>
</ul>
<section id="load-a-model-tokenizer" class="level2">
<h2 class="anchored" data-anchor-id="load-a-model-tokenizer">Load a model &amp; tokenizer</h2>
<section id="chat-versionì€-txt-ì£¼ê³ -ë°›ëŠ”-ëª¨ë¸" class="level3">
<h3 class="anchored" data-anchor-id="chat-versionì€-txt-ì£¼ê³ -ë°›ëŠ”-ëª¨ë¸">1. chat versionì€ txt ì£¼ê³  ë°›ëŠ” ëª¨ë¸</h3>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> <span class="st">"meta-llama/Llama-2-7b-chat-hf"</span></span></code></pre></div>
</div>
<p><code>AutoTokenizer.from_pretrained</code></p>
<ul>
<li>ì‚¬ì „ í›ˆë ¨ëœ model ê°€ì ¸ì™€</li>
<li>ì¸ì¦í•œ tokenizerë¥¼ ìë™ìœ¼ë¡œ ì„ íƒí•˜ê³  ì‚¬ìš©</li>
</ul>
<p><em>ê¼­ ëª¨ë¸ì„ ì§€ì •í•´ì£¼ê³  ì…ë ¥, ë°”ë¡œ ëª¨ë¸ì„ pretraindedì— ë„£ìœ¼ë©´ ì—ëŸ¬ ëœ¸</em></p>
<div class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    model,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    use_auth_token<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<p>transformers.pipeline</p>
<ul>
<li>ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ê³¼ tokenizerë¥¼ ìë™ìœ¼ë¡œ ì„ íƒ</li>
<li><code>torch_dtype</code>=torch.float16 ë°ì´í„° íƒ€ì… ì§€ì •</li>
<li><code>"text-generation"</code> ì“°ë©´ ì…ë ¥ ë¬¸ì¥ ì´ì–´ì„œ í…ìŠ¤íŠ¸ ìƒì„±í•˜ë„ë¡ í•¨.</li>
<li><code>device_map="auto"</code> ì“°ë©´ gpu í˜¹ì€ cpu ìë™ í• ë‹¹</li>
</ul>
<div class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> transformers.pipeline(</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text-generation"</span>,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    torch_dtype<span class="op">=</span>torch.float32,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># device_map="gpu"</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05&lt;00:00,  2.53s/it]</code></pre>
</div>
</div>
<p><code>"text-generation"</code>ì´ì™¸ì— ì“¸ ìˆ˜ ìˆëŠ” task option ë“¤</p>
<p>task (<code>str</code>): The task defining which pipeline will be returned. Currently accepted tasks are:</p>
<pre><code>        - `"audio-classification"`: will return a [`AudioClassificationPipeline`].
        - `"automatic-speech-recognition"`: will return a [`AutomaticSpeechRecognitionPipeline`].
        - `"conversational"`: will return a [`ConversationalPipeline`].
        - `"depth-estimation"`: will return a [`DepthEstimationPipeline`].
        - `"document-question-answering"`: will return a [`DocumentQuestionAnsweringPipeline`].
        - `"feature-extraction"`: will return a [`FeatureExtractionPipeline`].
        - `"fill-mask"`: will return a [`FillMaskPipeline`]:.
        - `"image-classification"`: will return a [`ImageClassificationPipeline`].
        - `"image-segmentation"`: will return a [`ImageSegmentationPipeline`].
        - `"image-to-text"`: will return a [`ImageToTextPipeline`].
        - `"mask-generation"`: will return a [`MaskGenerationPipeline`].
        - `"object-detection"`: will return a [`ObjectDetectionPipeline`].
        - `"question-answering"`: will return a [`QuestionAnsweringPipeline`].
        - `"summarization"`: will return a [`SummarizationPipeline`].
        - `"table-question-answering"`: will return a [`TableQuestionAnsweringPipeline`].
        - `"text2text-generation"`: will return a [`Text2TextGenerationPipeline`].
        - `"text-classification"` (alias `"sentiment-analysis"` available): will return a
          [`TextClassificationPipeline`].
        - `"text-generation"`: will return a [`TextGenerationPipeline`]:.
        - `"token-classification"` (alias `"ner"` available): will return a [`TokenClassificationPipeline`].
        - `"translation"`: will return a [`TranslationPipeline`].
        - `"translation_xx_to_yy"`: will return a [`TranslationPipeline`].
        - `"video-classification"`: will return a [`VideoClassificationPipeline`].
        - `"visual-question-answering"`: will return a [`VisualQuestionAnsweringPipeline`].
        - `"zero-shot-classification"`: will return a [`ZeroShotClassificationPipeline`].
        - `"zero-shot-image-classification"`: will return a [`ZeroShotImageClassificationPipeline`].
        - `"zero-shot-audio-classification"`: will return a [`ZeroShotAudioClassificationPipeline`].
        - `"zero-shot-object-detection"`: will return a [`ZeroShotObjectDetectionPipeline`].</code></pre>
<div class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gen(x, max_length<span class="op">=</span><span class="dv">200</span>):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    sequences <span class="op">=</span> pipeline(</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>        x,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        do_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        top_k<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        num_return_sequences<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        eos_token_id<span class="op">=</span>tokenizer.eos_token_id,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>max_length,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sequences[<span class="dv">0</span>][<span class="st">"generated_text"</span>].replace(x, <span class="st">""</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(gen(<span class="st">'I liked "Breaking Bad" and "Band of Brothers". Do you have any recommendations of other shows I might like?</span><span class="ch">\n</span><span class="st">'</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Answer: Yes, definitely! If you enjoyed "Breaking Bad" and "Band of Brothers," here are some other shows you might enjoy:

1. "The Sopranos" - This HBO series is a crime drama that follows the life of a New Jersey mob boss, Tony Soprano, as he navigates the criminal underworld and deals with personal and family issues.

2. "The Wire" - This HBO series explores the drug trade in Baltimore from multiple perspectives, including law enforcement, drug dealers, and politicians. It's known for its gritty realism and complex characters.

3. "Mad Men" - Set in the 1960s, this AMC series follows the lives ofĞ±Ğ°Ğ´ advertising execut</code></pre>
</div>
</div>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(gen(<span class="st">"ëŒ€í•œë¯¼êµ­ì—ì„œ ìœ ëª…í•œ ì¸ê³µì§€ëŠ¥ ìœ íŠœë²„ 3ëª…ë§Œ ë‚˜ì—´í•´ë´."</span>, <span class="dv">500</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>

1. ë¸”ë™íŒŒí‹° (Black Party) - ì•½ 200ë§Œ subscribe, 3000ë§Œ ì¡°íšŒìˆ˜
2. í”„ë¡œì íŠ¸ (Project) - ì•½ 150ë§Œ subscribe, 2000ë§Œ ì¡°íšŒìˆ˜
3. íŒŒì´ë„ (Final) - ì•½ 100ë§Œ subscribe, 1500ë§Œ ì¡°íšŒìˆ˜</code></pre>
</div>
</div>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(gen(<span class="st">"ìœ íŠœë¸Œ ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„?"</span>, <span class="dv">500</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
 (2023-02-17)  

ğŸ‘€ ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ¤”

ğŸ’¡ YouTube ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ¯

ğŸ” ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ”

ğŸ“¢ ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ“¢

ğŸ‘‰ ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ‘ˆ

ğŸ¤ ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ¤

ğŸ¯ ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ¯

ğŸ‘ ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ‘

ğŸ¤” ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ¤”

ğŸ‘€ ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ‘€

ğŸ“¢ ë¹µí˜•ì˜ ê°œë°œë„ìƒêµ­ ì±„ë„ ì•Œì•„? ğŸ“¢

ğŸ¤ ï¿½</code></pre>
</div>
</div>
</section>
<section id="ë‹¨ìˆœ-txt-ìƒì„±í•˜ëŠ”-ëª¨ë¸" class="level3">
<h3 class="anchored" data-anchor-id="ë‹¨ìˆœ-txt-ìƒì„±í•˜ëŠ”-ëª¨ë¸">2. ë‹¨ìˆœ txt ìƒì„±í•˜ëŠ” ëª¨ë¸</h3>
<div class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> <span class="st">"meta-llama/Llama-2-7b-hf"</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>tokenizer2 <span class="op">=</span> AutoTokenizer.from_pretrained(</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    model2,</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    use_auth_token<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>pipeline2 <span class="op">=</span> transformers.pipeline(</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text-generation"</span>,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model2,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    torch_dtype<span class="op">=</span>torch.float32,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># device_map="auto",</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:05&lt;00:00,  2.62s/it]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gen2(x, max_length<span class="op">=</span><span class="dv">200</span>):</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    sequences <span class="op">=</span> pipeline2(</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>        x,</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>        do_sample<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>        top_k<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        num_return_sequences<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        eos_token_id<span class="op">=</span>tokenizer2.eos_token_id,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>max_length,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sequences[<span class="dv">0</span>][<span class="st">"generated_text"</span>].replace(x, <span class="st">""</span>)</span></code></pre></div>
</div>
<div class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(gen2(<span class="st">'I liked "Breaking Bad" and "Band of Brothers". Do you have any recommendations of other shows I might like?</span><span class="ch">\n</span><span class="st">'</span>))</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>I'm a fan of "The Wire" and "The Sopranos" but I'm not sure if you're into gangster movies.
I'm not sure if you're into gangster movies.
I'm a fan of "The Wire" and "The Sopranos"
I'm not a big fan of gangster movies. I've seen a few and they are OK but I don't go out of my way to watch them. I'm not sure if I've ever seen "The Wire" or "The Sopranos".
I'm not sure if I've ever seen "The Wire" or "The Sopranos".
I'm a big fan of "The Wire" and</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="feature-extraction" class="level1">
<h1>feature-extraction</h1>
<ul>
<li><p>ref: checkpoint ì‚¬ìš© ê°€ëŠ¥ https://huggingface.co/models?pipeline_tag=feature-extraction</p></li>
<li><p><code>checkpoint</code> ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ì§€ì •í•˜ê¸°, ìœ„ì— 400ê°œ ì´ìƒì˜ ëª¨ë¸ ì¡´ì¬</p></li>
<li><p><code>framework="pt"</code>or - <code>framework=True</code> íŒŒì´í† ì¹˜ ì´ìš©í•˜ê² ë‹¤.</p></li>
<li><p><code>framework="tf"</code> ë¼ë©´ í…ì„œí”Œë¡œìš° ì´ìš©í•˜ê² ë‹¤.</p>
<ul>
<li>framework ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ëª¨ë¸..ë‹¤ ì ìš©ë˜ì§€ëŠ” ì•ŠëŠ”ë‹¤.</li>
</ul></li>
</ul>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>checkpoint <span class="op">=</span> <span class="st">"facebook/bart-base"</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> AutoTokenizer.from_pretrained(<span class="st">'distilroberta-base'</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>feature_extractor <span class="op">=</span> transformers.pipeline(<span class="st">"feature-extraction"</span>,framework<span class="op">=</span><span class="st">"pt"</span>,model<span class="op">=</span>checkpoint,tokenizer<span class="op">=</span>tokenizer)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"Transformers is an awesome library!"</span></span></code></pre></div>
</div>
<section id="ê³µì‹-ì˜ˆì œ" class="level2">
<h2 class="anchored" data-anchor-id="ê³µì‹-ì˜ˆì œ">ê³µì‹ ì˜ˆì œ</h2>
<section id="íŠ¹ì§•í™”-1textì—ì„œ-íŠ¹ì§•-ì¶”ì¶œ" class="level3">
<h3 class="anchored" data-anchor-id="íŠ¹ì§•í™”-1textì—ì„œ-íŠ¹ì§•-ì¶”ì¶œ">íŠ¹ì§•í™” 1(textì—ì„œ íŠ¹ì§• ì¶”ì¶œ)</h3>
<ul>
<li>9ê°œì˜ í† í°ìœ¼ë¡œ ë¶„ë¦¬ëŒ.</li>
<li>768ì°¨ì›</li>
</ul>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Reducing along the first dimension to get a 768 dimensional array</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>feature_extractor(text,return_tensors <span class="op">=</span> <span class="st">"pt"</span>)[<span class="dv">0</span>].shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>torch.Size([9, 768])</code></pre>
</div>
</div>
<ul>
<li>feature_extractorì˜ ê²°ê³¼ëŠ” torchë¡œ ì§€ì •í•´ì¤˜ì„œ torch ë¡œ ë‚˜ì˜´</li>
</ul>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>feature_extractor(text,return_tensors <span class="op">=</span> <span class="st">"pt"</span>)[<span class="dv">0</span>].numpy().mean(axis<span class="op">=</span><span class="dv">0</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>(768,)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>feature_extractor(text,return_tensors <span class="op">=</span> <span class="st">"pt"</span>)[<span class="dv">0</span>].numpy().mean(axis<span class="op">=</span><span class="dv">1</span>).shape</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>(9,)</code></pre>
</div>
</div>
<ul>
<li>íŠ¹ì§• ì¶”ì¶œ</li>
</ul>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>plt.plot(feature_extractor(text,return_tensors <span class="op">=</span> <span class="st">"pt"</span>)[<span class="dv">0</span>].numpy().mean(axis<span class="op">=</span><span class="dv">0</span>)) <span class="co"># íŠ¹ì§• ì¶”ì¶œ</span></span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2023-09-08-llama2_files/figure-html/cell-17-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>pd.DataFrame(feature_extractor(text,return_tensors <span class="op">=</span> <span class="st">"pt"</span>)[<span class="dv">0</span>].numpy().mean(axis<span class="op">=</span><span class="dv">0</span>)).describe()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>0</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>768.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.083737</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.882607</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-4.869781</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-0.423363</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.095451</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.632395</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2.976899</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>feature_extractor(text,return_tensors <span class="op">=</span> <span class="st">"pt"</span>)[<span class="dv">0</span>].numpy().mean(axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>array([0.04353118, 0.07581159, 0.0764325 , 0.09305001, 0.08523342,
       0.09044287, 0.09453633, 0.09341192, 0.10118499], dtype=float32)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>np.array(feature_extractor.predict(<span class="st">"I do not know"</span>)[<span class="dv">0</span>]).mean(axis<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>array([0.04564792, 0.0685828 , 0.09174387, 0.08442586, 0.09680472,
       0.0981098 ])</code></pre>
</div>
</div>
</section>
<section id="íŠ¹ì§•í™”-2í† í°í™”í•œ-í›„-íŠ¹ì§•-ì¶”ì¶œ" class="level3">
<h3 class="anchored" data-anchor-id="íŠ¹ì§•í™”-2í† í°í™”í•œ-í›„-íŠ¹ì§•-ì¶”ì¶œ">íŠ¹ì§•í™” 2(í† í°í™”í•œ í›„ íŠ¹ì§• ì¶”ì¶œ)</h3>
<div class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>inputs <span class="op">=</span> tokenizer(text,return_tensors<span class="op">=</span><span class="st">"pt"</span>,max_length<span class="op">=</span><span class="dv">9</span>)<span class="op">;</span>inputs</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>{'input_ids': tensor([[    0, 44820,   268,    16,    41,  6344,  5560,   328,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(inputs.input_ids[<span class="dv">0</span>]), <span class="bu">len</span>(inputs.attention_mask[<span class="dv">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>(9, 9)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>inputs[<span class="dv">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>Encoding(num_tokens=9, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>tokenizer.decode(inputs.input_ids[<span class="dv">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>'&lt;s&gt;Transformers is an awesome library!&lt;/s&gt;'</code></pre>
</div>
</div>
<ul>
<li>íŠ¹ì§• ì¶”ì¶œ(outputs[0][0]~outputs[0][4] ê¹Œì§€ ì¡´ì¬)</li>
</ul>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> feature_extractor(<span class="op">*</span>inputs)<span class="op">;</span>plt.plot(outputs[<span class="dv">0</span>][<span class="dv">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Ignoring args : ('attention_mask',)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2023-09-08-llama2_files/figure-html/cell-25-output-2.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(outputs[<span class="dv">0</span>][<span class="dv">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>768</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="fine-tuning" class="level1">
<h1>Fine-tuning</h1>
<p>https://github.com/facebookresearch/llama-recipes</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>